{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Setting the style of the plot\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Creating an array of input sizes\n",
    "n = 10\n",
    "x = np.arange(1, n)\n",
    "\n",
    "# Creating a pandas data frame for popular complexity classes\n",
    "df = pd.DataFrame({'x': x,\n",
    "                   'O(1)': 0,\n",
    "                   'O(n)': x,\n",
    "                   'O(log_n)': np.log(x),\n",
    "                   'O(n_log_n)': n * np.log(x),\n",
    "                   'O(n2)': np.power(x, 2), # Quadratic\n",
    "                   'O(n3)': np.power(x, 3)}) # Cubic\n",
    "\n",
    "# Creating labels\n",
    "labels = ['$O(1) - Constant$',\n",
    "          '$O(\\log{}n) - Logarithmic$',\n",
    "          '$O(n) - Linear$',\n",
    "          '$O(n^2) - Quadratic$',\n",
    "          '$O(n^3) - Cubic$',\n",
    "          '$O(n\\log{}n) - N log n$']\n",
    "\n",
    "# Plotting every column in dataframe except 'x'\n",
    "for i, col in enumerate(df.columns.drop('x')):\n",
    "    print(labels[i], col)\n",
    "    plt.plot(df[col], label=labels[i])\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Limiting the y-axis\n",
    "plt.ylim(0,50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple measure of training and scoring time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from time import time\n",
    "\n",
    "@contextmanager\n",
    "def timer():\n",
    "    s = time()\n",
    "    yield\n",
    "    e = time() - s\n",
    "    print(\"{0}: {1} ms\".format('Elapsed time', e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with timer():\n",
    "    X = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Defining properties of dataset\n",
    "nT = 100000000 # Total number of values in our dataset\n",
    "nF = 10 # Number of features\n",
    "nE = int(nT / nF) # Number of examples\n",
    "\n",
    "# Creating n x m matrix where n=100 and m=10\n",
    "X = np.random.rand(nT).reshape(nE, nF)\n",
    "\n",
    "# This will be a binary classification with labels 0 and 1\n",
    "y = np.random.randint(2, size=nE)\n",
    "\n",
    "# Data that we are going to score\n",
    "scoring_data = np.random.rand(nF).reshape(1,-1)\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(11, algorithm='brute')\n",
    "\n",
    "# Measure training time\n",
    "with timer():\n",
    "    knn.fit(X, y)\n",
    "\n",
    "# Measure scoring time\n",
    "with timer():\n",
    "    knn.predict(scoring_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_res = LogisticRegression(C=1e5)\n",
    "\n",
    "with timer():\n",
    "    log_res.fit(X, y)\n",
    "\n",
    "with timer():\n",
    "    prediction = log_res.predict(scoring_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code profiling in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cProfile\n",
    "import cProfile\n",
    "\n",
    "cProfile.run('np.std(np.random.rand(1000000))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing performance statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "# This function will scale training datatse and train given classifier.\n",
    "# Based on predictions it will draw decision boundaries.\n",
    "\n",
    "def draw_decision_boundary(clf, X, y, h = .01, figsize=(9,9), boundary_cmap=cm.winter, points_cmap=cm.cool):\n",
    "\n",
    "    # After you apply StandardScaler, feature means will be removed and all features will have unit variance.\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Splitting dataset to train and test sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    # Training given estimator on training dataset by invoking fit function.\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Each estimator has a score function.\n",
    "    # Score will show you estimator's performance by showing metric suitable to given classifier.\n",
    "    # For example, for linear regression, it will output coefficient of determination R^2 of the prediction.\n",
    "    # For logistic regression, it will output mean accuracy.\n",
    "\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"Score: %0.3f\" % score)\n",
    "\n",
    "    # Predict function of an estimator, will predict using trained model\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    # Figure is a high-level container that contains plot elements\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "\n",
    "    # In current figure, subplot will create Axes based on given arguments (nrows, ncols, index)\n",
    "    ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "    # Calculating min/max of axes\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    # Meshgrid is usually used to evaluate function on grid.\n",
    "    # It will allow you to create points to represent the space you operate\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Generate predictions for all the point-pair created by meshgrid\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # This will draw boundary\n",
    "    ax.contourf(xx, yy, Z, cmap=boundary_cmap)\n",
    "\n",
    "    # Plotting training data\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=points_cmap, edgecolors='k')\n",
    "\n",
    "    # Potting testing data\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=points_cmap, alpha=0.6, edgecolors='k')\n",
    "\n",
    "    # Showing your masterpiece\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# sklearn.linear_model includes regression models where target variable is a linear combination of input variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# make_moons is another useful function to generate sample data\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=1000, noise=0.1, random_state=0)\n",
    "\n",
    "# Plot sample data\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=cm.cool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_decision_boundary(LogisticRegression(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "draw_decision_boundary(RandomForestClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set context helps you to adjust things like label size, lines and various elements\n",
    "# Try \"notebook\", \"talk\" or \"paper\" instead of \"poster\" to see how it changes\n",
    "sns.set_context('poster')\n",
    "\n",
    "# set_color_codes will affect how colors such as 'r', 'b', 'g' will be interpreted\n",
    "sns.set_color_codes()\n",
    "\n",
    "# Plot keyword arguments will allow you to set things like size or line width to be used in charts.\n",
    "plot_kwargs = {'s': 10, 'linewidths': 0.1}\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pprint will better output your variables in console for readability\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# Creating sample dataset using sklearn samples_generator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Make blobs will generate isotropic Gaussian blobs\n",
    "# You can play with arguments like center of blobs, cluster standard deviation\n",
    "centers = [[2, 1], [-1.5, -1], [1, -1], [-2, 2]]\n",
    "cluster_std = [0.1, 0.1, 0.1, 0.1]\n",
    "\n",
    "# Sample data will help you to see your algorithms behavior\n",
    "X, y = make_blobs(n_samples=1000,\n",
    "                  centers=centers,\n",
    "                  cluster_std=cluster_std,\n",
    "                  random_state=53)\n",
    "\n",
    "# Plot generated sample data\n",
    "plt.scatter(X[:, 0], X[:, 1], **plot_kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_std = [0.4, 0.5, 0.6, 0.5] \n",
    "\n",
    "X, y = make_blobs(n_samples=1000,\n",
    "                  centers=centers,\n",
    "                  cluster_std=cluster_std,\n",
    "                  random_state=53)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], **plot_kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unsupervised_AutoML:\n",
    "\n",
    "    def __init__(self, estimators=None, transformers=None):\n",
    "        self.estimators = estimators\n",
    "        self.transformers = transformers\n",
    "        pass\n",
    "    \n",
    "    def fit_predict(self, X, y=None):\n",
    "        \"\"\"\n",
    "        fit_predict will train given estimator(s) and predict cluster membership for each sample\n",
    "        \"\"\"\n",
    "\n",
    "        # This dictionary will hold predictions for each estimator\n",
    "        predictions = []\n",
    "        performance_metrics = {}\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            labels = estimator['estimator'](*estimator['args'], **estimator['kwargs']).fit_predict(X)\n",
    "            estimator['estimator'].n_clusters_ = len(np.unique(labels))\n",
    "            metrics = self._get_cluster_metrics(estimator['estimator'].__name__, estimator['estimator'].n_clusters_, X, labels, y)\n",
    "            predictions.append({estimator['estimator'].__name__: labels})\n",
    "            performance_metrics[estimator['estimator'].__name__] = metrics\n",
    "            \n",
    "        self.predictions = predictions\n",
    "        self.performance_metrics = performance_metrics\n",
    "\n",
    "        return predictions, performance_metrics\n",
    "    \n",
    "    # Printing cluster metrics for given arguments\n",
    "    def _get_cluster_metrics(self, name, n_clusters_, X, pred_labels, true_labels=None):\n",
    "        from sklearn.metrics import homogeneity_score, \\\n",
    "            completeness_score, \\\n",
    "            v_measure_score, \\\n",
    "            adjusted_rand_score, \\\n",
    "            adjusted_mutual_info_score, \\\n",
    "            silhouette_score\n",
    "\n",
    "        print(\"\"\"################## %s metrics #####################\"\"\" % name)\n",
    "        if len(np.unique(pred_labels)) >= 2:\n",
    "\n",
    "            silh_co = silhouette_score(X, pred_labels)\n",
    "\n",
    "            if true_labels is not None:\n",
    "\n",
    "                h_score = homogeneity_score(true_labels, pred_labels)\n",
    "                c_score = completeness_score(true_labels, pred_labels)\n",
    "                vm_score = v_measure_score(true_labels, pred_labels)\n",
    "                adj_r_score = adjusted_rand_score(true_labels, pred_labels)\n",
    "                adj_mut_info_score = adjusted_mutual_info_score(true_labels, pred_labels)\n",
    "\n",
    "                metrics = {\"Silhouette Coefficient\": silh_co,\n",
    "                           \"Estimated number of clusters\": n_clusters_,\n",
    "                           \"Homogeneity\": h_score,\n",
    "                           \"Completeness\": c_score,\n",
    "                           \"V-measure\": vm_score,\n",
    "                           \"Adjusted Rand Index\": adj_r_score,\n",
    "                           \"Adjusted Mutual Information\": adj_mut_info_score}\n",
    "\n",
    "                for k, v in metrics.items():\n",
    "                    print(\"\\t%s: %0.3f\" % (k, v))\n",
    "\n",
    "                return metrics\n",
    "\n",
    "            metrics = {\"Silhouette Coefficient\": silh_co,\n",
    "                       \"Estimated number of clusters\": n_clusters_}\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                print(\"\\t%s: %0.3f\" % (k, v))\n",
    "\n",
    "            return metrics\n",
    "\n",
    "        else:\n",
    "            print(\"\\t# of predicted labels is {}, can not produce metrics. \\n\".format(np.unique(pred_labels)))\n",
    "            \n",
    "    # plot_clusters will visualize the clusters given predicted labels\n",
    "    def plot_clusters(self, estimator, X, labels, plot_kwargs):\n",
    "\n",
    "        palette = sns.color_palette('deep', np.unique(labels).max() + 1)\n",
    "        colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in labels]\n",
    "\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=colors, **plot_kwargs)\n",
    "        plt.title('{} Clusters'.format(str(estimator.__name__)), fontsize=14)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_all_clusters(self, estimators, labels, X, plot_kwargs):\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        for i, algorithm in enumerate(labels):\n",
    "\n",
    "            quotinent = np.divide(len(estimators), 2)\n",
    "\n",
    "            # Simple logic to decide row and column size of the figure\n",
    "            if isinstance(quotinent, int):\n",
    "                dim_1 = 2\n",
    "                dim_2 = quotinent\n",
    "            else:\n",
    "                dim_1 = np.ceil(quotinent)\n",
    "                dim_2 = 3\n",
    "\n",
    "            palette = sns.color_palette('deep',\n",
    "                                        np.unique(algorithm[estimators[i]['estimator'].__name__]).max() + 1)\n",
    "            colors = [palette[x] if x >= 0 else (0.0, 0.0, 0.0) for x in\n",
    "                      algorithm[estimators[i]['estimator'].__name__]]\n",
    "\n",
    "            plt.subplot(dim_1, dim_2, i + 1)\n",
    "            plt.scatter(X[:, 0], X[:, 1], c=colors, **plot_kwargs)\n",
    "            plt.title('{} Clusters'.format(str(estimators[i]['estimator'].__name__)), fontsize=8)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "estimators = [{'estimator': KMeans, 'args':(), 'kwargs':{'n_clusters': 4}}]\n",
    "\n",
    "unsupervised_learner = Unsupervised_AutoML(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsupervised_learner.estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, performance_metrics = unsupervised_learner.fit_predict(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = {'s': 12, 'linewidths': 0.1}\n",
    "unsupervised_learner.plot_clusters(KMeans,\n",
    "                                   X,\n",
    "                                   unsupervised_learner.predictions[0]['KMeans'],\n",
    "                                   plot_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=2000, centers=5, cluster_std=[1.7, 0.6, 0.8, 1.0, 1.2], random_state=220)\n",
    "\n",
    "# Plot sample data\n",
    "plt.scatter(X[:, 0], X[:, 1], **plot_kwargs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "estimators = [{'estimator': KMeans, 'args':(), 'kwargs':{'n_clusters': 4}}]\n",
    "\n",
    "unsupervised_learner = Unsupervised_AutoML(estimators)\n",
    "\n",
    "predictions, performance_metrics = unsupervised_learner.fit_predict(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = {'s': 12, 'linewidths': 0.1}\n",
    "unsupervised_learner.plot_clusters(KMeans,\n",
    "                                   X,\n",
    "                                   unsupervised_learner.predictions[0]['KMeans'],\n",
    "                                   plot_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "estimators = [{'estimator': DBSCAN, 'args':(), 'kwargs':{'eps': 0.5}}]\n",
    "\n",
    "unsupervised_learner = Unsupervised_AutoML(estimators)\n",
    "\n",
    "predictions, performance_metrics = unsupervised_learner.fit_predict(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = {'s': 12, 'linewidths': 0.1}\n",
    "unsupervised_learner.plot_clusters(DBSCAN,\n",
    "                                   X,\n",
    "                                   unsupervised_learner.predictions[0]['DBSCAN'],\n",
    "                                   plot_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "estimators = [{'estimator': AgglomerativeClustering, 'args':(), 'kwargs':{'n_clusters': 4, 'linkage': 'ward'}}]\n",
    "\n",
    "unsupervised_learner = Unsupervised_AutoML(estimators)\n",
    "\n",
    "predictions, performance_metrics = unsupervised_learner.fit_predict(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = {'s': 12, 'linewidths': 0.1}\n",
    "unsupervised_learner.plot_clusters(AgglomerativeClustering,\n",
    "                                   X,\n",
    "                                   unsupervised_learner.predictions[0]['AgglomerativeClustering'],\n",
    "                                   plot_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing high-dimensional datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wisconsin Breast Cancer Diagnostic Dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "pca = pca.fit_transform(df)\n",
    "\n",
    "plt.scatter(pca[:, 0], pca[:, 1], c=data.target, cmap=\"RdBu_r\", edgecolor=\"Red\", alpha=0.35)\n",
    "plt.colorbar()\n",
    "plt.title('PCA, n_components=2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pre-process data.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "preprocessed_data = scaler.transform(df)\n",
    "scaled_features_df = pd.DataFrame(preprocessed_data, index=df.index, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "pca = pca.fit_transform(scaled_features_df)\n",
    "\n",
    "plt.scatter(pca[:, 0], pca[:, 1], c=data.target, cmap=\"RdBu_r\", edgecolor=\"Red\", alpha=0.35)\n",
    "plt.colorbar()\n",
    "plt.title('PCA, n_components=2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(verbose=1, perplexity=40, n_iter=4000)\n",
    "tsne = tsne.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne[:, 0], tsne[:, 1], c=data.target, cmap=\"winter\", edgecolor=\"None\", alpha=0.35)\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(verbose=1, perplexity=40, n_iter=4000)\n",
    "tsne = tsne.fit_transform(scaled_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsne[:, 0], tsne[:, 1], c=data.target, cmap=\"winter\", edgecolor=\"None\", alpha=0.35)\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
