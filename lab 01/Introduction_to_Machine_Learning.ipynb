{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is AutoML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn has convenient modules to create sample data.\n",
    "# make_blobs will help us to create a sample data set suitable for clustering\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=100, centers=2, cluster_std=0.30, random_state=0)\n",
    "\n",
    "# Let's visualize what we have first\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will import KMeans model from clustering model family of Sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_means = KMeans(n_clusters=2)\n",
    "k_means.fit(X)\n",
    "predictions = k_means.predict(X)\n",
    "\n",
    "# Let's plot the predictions\n",
    "plt.scatter(X[:, 0], X[:, 1], c=predictions, cmap='brg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# First dataset contains the basic information for databases.\n",
    "databases_df = pd.DataFrame({\"database_id\": [2234, 1765, 8796, 2237, 3398],\n",
    "\"creation_date\": [\"2018-02-01\", \"2017-03-02\", \"2017-05-03\", \"2013-05-12\", \"2012-05-09\"]})\n",
    "\n",
    "databases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second dataset contains the information of transaction for each database id\n",
    "db_transactions_df = pd.DataFrame({\"transaction_id\": [26482746, 19384752, 48571125, 78546789, 19998765, 26482646, 12484752, 42471125, 75346789, 16498765, 65487547, 23453847, 56756771, 45645667, 23423498, 12335268, 76435357, 34534711, 45656746, 12312987],\n",
    "                \"database_id\": [2234, 1765, 2234, 2237, 1765, 8796, 2237, 8796, 3398, 2237, 3398, 2237, 2234, 8796, 1765, 2234, 2237, 1765, 8796, 2237],\n",
    "                \"transaction_size\": [10, 20, 30, 50, 100, 40, 60, 60, 10, 20, 60, 50, 40, 40, 30, 90, 130, 40, 50, 30],\n",
    "                \"transaction_date\": [\"2018-02-02\", \"2018-03-02\", \"2018-03-02\", \"2018-04-02\", \"2018-04-02\", \"2018-05-02\", \"2018-06-02\", \"2018-06-02\", \"2018-07-02\", \"2018-07-02\", \"2018-01-03\", \"2018-02-03\", \"2018-03-03\", \"2018-04-03\", \"2018-04-03\", \"2018-07-03\", \"2018-07-03\", \"2018-07-03\", \"2018-08-03\", \"2018-08-03\"]})\n",
    "\n",
    "db_transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities for each of datasets should be defined\n",
    "entities = {\n",
    "\"databases\" : (databases_df, \"database_id\"),\n",
    "\"transactions\" : (db_transactions_df, \"transaction_id\")\n",
    "}\n",
    "\n",
    "# Relationships between tables should also be defined as below\n",
    "relationships = [(\"databases\", \"database_id\", \"transactions\", \"database_id\")]\n",
    "\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Digits dataset that you have used in Auto-sklearn example\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target,\n",
    "                                                    train_size=0.75, test_size=0.25)\n",
    "\n",
    "# You will create your TPOT classifier with commonly used arguments\n",
    "tpot = TPOTClassifier(generations=10, population_size=30, verbosity=2)\n",
    "\n",
    "# When you invoke fit method, TPOT will create generations of populations, seeking best set of parameters. Arguments you have used to create TPOTClassifier such as generaions and population_size will affect the search space and resulting pipeline.\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "print(tpot.score(X_test, y_test))\n",
    "# 0.9834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('my_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat my_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=6, min_samples_leaf=2, min_samples_split=2)),\n",
    "    KNeighborsClassifier(n_neighbors=2, weights=\"distance\")\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(X_train, y_train)\n",
    "results = exported_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
